#######################################################################
######          Cross-Validation and Spatial Variability         ######
######                Pixel Based - for rasters                  ######
######                        06/04/18                           ######
#######################################################################

#######################################################################
######                    Setup and data                         ######
#######################################################################
######                Load required libraries                    ######

require(foreign)       # version 0.8-66
require(rgeos)         # version 0.3-17
require(rgdal)         # version 1.1-3
require(maptools)      # version 0.8-39
require(ggplot2)       # version 2.2.1
require(plyr)          # version 1.8.3
require(GGally)        # version 1.3.0
require(biomod2)       # version 3.1-64
require(caret)         # version 6.0-64
require(e1071)         # version 1.6-7
require(grid)          # version 3.2.3
require(party)         # version 1.0-25
require(matrixStats)   # version 0.52.2
require(caTools)       # version 1.17.1
require(vegan)         # version 2.4-4

######            Load data and set working directory            ######

### Set workspace
setwd("C:/Data") # Input workspace path

### Read training data in from file
sdata <- read.csv("Example_data.csv")     # Data with response variable (classes as factor variable) 
                                    # in first column, followed by predictors

str(sdata)
#View(sdata)
summary(sdata)

# Reorder factor variable to remove unused levels - rename levels if required
sdata[[1]] <- factor(sdata[[1]]) # factor(x, levels, labels = levels)

# Define the number of class levels
numclass <- nlevels(sdata[[1]])

### Read raster data for predicting  #raster files should have the same file name as csv column names
require(raster)
f <- list.files(path='F:/Data', pattern='.tif$', full.names=T) #Location of raster files
s1 <- stack(f,RAT=F)
s1
plot(s1)

# raster data as a dataframe
s1d <- as(as(s1, "SpatialPointsDataFrame"), "data.frame")

### Specify colours to be used for classes in plots, including 'overall' as last class
# View levels
levels(sdata[[1]])
# Set colours
#classpal <- "grey40" # All the same level of grey as a default
classpal <- c("#FF4040","#E9967A","#FF8C00","#EEDD82") # Define specific 

#######################################################################
######                     Model specification                   ######
#######################################################################
### Variables selected for model on preselection step
predsel <-  c("back","bath","eastness","northnes","rdmv","slope")   # Need to specify relevant predictive layers
clms <- c(names(sdata[1]),predsel)

### Select modelling method
modmethod <- "rf"     # specify modelling method - see 'caret' list of availablle models      
                      # e.g. 'rf', 'knn', 'gam','ctree'
                        #'treebag' is bagged CART model

### Specify formula and model specific inputs, where appropriate
fml <- BSH_CODE~.              # Specify model formula y~x as appropriate for chosen method

ctl <- NULL         # model specific inputs
  
                    # e.g, for ctree
                    # ctree_control(teststat = "quad",           
                    # testtype = "Univariate",
                    # mincriterion = 0.90, 
                    # minsplit = 3, minbucket = 3,
                    # maxdepth = 5)

### Insert number of crossvalidation runs required
nruns <- 25 

preds <- predsel           # List predictor variables to 
                    # be included in model - based 
                    # on preselection
                                                                  
###### Scatterplot matrix to look at correlations between variables ######

jpeg("ModelVarsScatterMatrix.jpg",width = 25,height = 20,units = "cm",res = 400)
require(GGally)
p <- ggpairs(data=sdata,
             lower=list(continuous="smooth"), 
             diag=list(continuous= "barDiag"),
             upper=list(continuous='cor'))
 
p
dev.off()
#######################################################################
######  Build a set of crossvalidated models with training data  ######
#######################################################################
###  Create a list with train and test datasets for the crossvalidation runs

require(caTools)
require(vegan)

Y <- sdata[[1]]
train.sets <- list()
test.sets <- list()

for (j in 1:nruns){ 
  msk= sample.split( Y, SplitRatio = 7/10, group = NULL )### Define the ratio split of training and testing data
  table(Y, msk)
  train = sdata[ msk,] 
  test  = sdata[ !msk,]
  print(table(Y, msk))
  
  train.sets[[j]] <- train
  test.sets[[j]] <- test
  next}

### Create a list object with models using the train datasets

## Define model settings

ctrl <- trainControl(method = "none") # No model tuning

## Build a models - use any modelling method that produces outputs for 
## predicted class and probability of each class and takes

# Make a list object to save models in  
modlst <- list()

# Model runs
for (j in 1:nruns){  
  
  train <- train.sets[[j]]
  test <- test.sets[[j]]
  
  modlst[j] <- list(mod <- train(fml, 
                                 data=train, 
                                 method=modmethod,
                                 controls = ctl, 
                                 trControl=ctrl,
                                 tuneGrid = NULL, 
                                 tuneLength = 1)) 
  
  next
}

#View models
modlst
modlst[[1]]$finalModel

### Model validation

require(caret)

## Make dataframes to save validation results into

# Class specific validation statistics
class.res <- data.frame(Run=character(0),Class=character(0),
                        Sens=numeric(0),Spec=numeric(0),BA=numeric(0),
                        stringsAsFactors =F)

# Validation statistics for whole model
class.res.all <- data.frame(Run=character(0),
                            Acc=numeric(0),
                            NIR=numeric(0),
                            P=numeric(0),
                            Kappa=numeric(0),
                            Q=numeric(0),
                            A=numeric(0),
                            stringsAsFactors =F)

# Combined validations statistic
res.mat.all <- data.frame(ModRun = numeric(),Comb=character(),
                          Pred=character(),Obs=character(),Vals=numeric(),
                          stringsAsFactors = FALSE)

## Loop through the models runs to collect validation statistics including 
## overall accuracy (Acc), no information rate (NIR), p-value (p) for accuracy 
## exceeding no information rate, Kappa value (Kappa), quantity agreement (Q), 
## allocation agreement (A), Balanced Accuracy (BA) Specificity (Spec) and 
## Sensitivity (Sens)

for (i in 1:nruns){   
  
  results <- as.data.frame(rownames(test.sets[[i]]))
  results$actual <- test.sets[[i]][[1]]
  # Predict class with model i
  results$predicted <- predict(modlst[[i]],test.sets[[i]]) 
  names(results) <- c("id", "actual", "predicted")
  
  # Calculate confusion matrix for predictions by model i
  results.matrix <- confusionMatrix(results$predicted, results$actual)
  results.matrix
  
  # Get the number of objects predicted into each class by model i
  temp.pred <- predict(modlst[[i]],s1d,type="raw") 
  pctObj <- as.data.frame(summary(temp.pred)/sum(summary(temp.pred)))
  
  # Get values from confusion matrix for model i into a data frame for future plotting
  rnx <- 1
  res.mat.0 <- data.frame(ModRun = numeric(),Comb=character(),
                          Pred=character(),Obs=character(),Vals=numeric(),
                          ValsP=numeric(),
                          stringsAsFactors = FALSE)
  
  for (r in 1:dim(results.matrix$table)[1]){
    
    for (o in 1:dim(results.matrix$table)[2]){
      rn <- rnx+o-1
      res.mat.0[rn,1] <- i
      labt <- paste(r,o,sep="") 
      res.mat.0[rn,2] <- labt
      res.mat.0[rn,3] <- levels(train[[1]])[r]
      res.mat.0[rn,4] <- levels(train[[1]])[o]
      res.mat.0[rn,5] <- results.matrix$table[r,o]
      next
    }
    
    CurSel <- res.mat.0[(rn-o+1):rn,]
    PrVals <- res.mat.0[(rn-o+1):rn,5]
    totPrCL <- sum(res.mat.0[(rn-o+1):rn,5])
    
    res.mat.0[(rn-o+1):rn,6] <- round((PrVals/totPrCL) * pctObj [[1]][r],3)
    CurSel <- res.mat.0[(rn-o+1):rn,]
    
    labt <- paste(r,'U',sep="") 
    rn <- rn+1
    res.mat.0[rn,1] <- i
    res.mat.0[rn,2] <- labt
    res.mat.0[rn,3] <- levels(train[[1]])[r]
    res.mat.0[rn,4] <- 'U'
    res.mat.0[rn,5] <- round(100*(results.matrix$table[r,r]/rowSums(results.matrix$table)[r]),1)
    res.mat.0[rn,6] <- round(100*(CurSel[CurSel[3]==CurSel[4],6]/sum(CurSel[6])),3)
    
    rnx <- rnx+dim(results.matrix$table)[2]+1
    next
  }
  
  for (o in 1:dim(results.matrix$table)[2]){
    ObsClassVal <- res.mat.0[res.mat.0[1]==i & res.mat.0[4]==levels(train[[1]])[o] ,]
    rn <- rnx+o-1
    res.mat.0[rn,1] <- i
    labt <- paste('P',o,sep="") 
    res.mat.0[rn,2] <- labt
    res.mat.0[rn,3] <- 'P'
    res.mat.0[rn,4] <- levels(train[[1]])[o]
    res.mat.0[rn,5] <- round(100*(results.matrix$table[o,o]/colSums(results.matrix$table)[o]),1)
    res.mat.0[rn,6] <- round(100*(ObsClassVal[ObsClassVal[3]==ObsClassVal[4],6]/sum(ObsClassVal[1:4,6])),1)
    next
  }
  
  RunValAll <- res.mat.0[res.mat.0[1]==i,]
  RunValAll$Pred <- factor(RunValAll$Pred,levels = c(levels(train[[1]]),"P","U"))
  RunValAll$Obs <- factor(RunValAll$Obs,levels = c(levels(train[[1]]),"P","U"))
  RunValAll$ValsP[is.nan(RunValAll$ValsP) & RunValAll$Pred !="P" & RunValAll$Pred !="U"] <- 0
  RunValNum <- RunValAll[RunValAll[3]!="P" & RunValAll[4]!="U",]
  RunValCor <- RunValNum[RunValNum[3]==RunValNum[4],]
  Psum <- aggregate(ValsP~Pred,data=RunValNum,sum,na.action=na.pass)
  Osum <- aggregate(ValsP~Obs,data=RunValNum,sum,na.action=na.pass)
  
  res.mat.0[rn+1,1] <- i
  labt <- paste('P','U',sep="") 
  res.mat.0[rn+1,2] <- labt
  res.mat.0[rn+1,3] <- 'P'
  res.mat.0[rn+1,4] <- 'U'
  res.mat.0[rn+1,5] <- round(100*results.matrix[[3]][[1]],1)
  res.mat.0[rn+1,6] <- round(100*(sum(RunValCor[6])/sum(RunValNum[6])),3)
  
  res.mat.all <- rbind(res.mat.all,res.mat.0)
  
  require(matrixStats)   # add library
  sum(2*rowMins(as.matrix(cbind(Osum[2]-RunValCor[6],Psum[2]-RunValCor[6]))))/2
  
  # Get overall accuracy measures for model validation run i
  class.res.all[i,1] <- i
  class.res.all[i,2] <- results.matrix[[3]][[1]]
  class.res.all[i,3] <- results.matrix[[3]][[5]]
  class.res.all[i,4] <- results.matrix[[3]][[6]]
  class.res.all[i,5] <- results.matrix[[3]][[2]]
  class.res.all[i,6] <- sum(abs(Osum[2]-Psum[2]))/2
  class.res.all[i,7] <- sum(2*rowMins(as.matrix(cbind(Osum[2]-RunValCor[6],
                                                      Psum[2]-RunValCor[6]))))/2
  
  class.res.0 <- data.frame(Run=character(0),Class=character(0),
                            Sens=numeric(0),Spec=numeric(0),BA=numeric(0),
                            stringsAsFactors =F)
  
  # Get class-specific accuracy measures for model validation run i
  for (j in 1:numclass){
    
    class.res.0[j,1] <- i
    class.res.0[j,2] <- row.names(as.data.frame(results.matrix[[4]]))[j]
    class.res.0[j,3] <- as.data.frame(results.matrix[[4]])[j,1]
    class.res.0[j,4] <- as.data.frame(results.matrix[[4]])[j,2]
    class.res.0[j,5] <- as.data.frame(results.matrix[[4]])[j,8]
    
    next
  }
  
  class.res <- rbind(class.res,class.res.0)
  
  next
}

# Print overall accuracy results from all model runs
class.res.all
# Print class-specific accuracy results from all model runs
class.res
# Print confusion matrix values from all model runs
res.mat.all
res.mat.all$ValsP[is.nan(res.mat.all$ValsP) & res.mat.all$Pred !="P" & res.mat.all$Pred !="U"] <- 0
res.mat.all

### Write results to Excel file

require(xlsx)
require(rJava)
require(xlsxjars)
write.xlsx(class.res.all, "CrossValResults.xlsx", sheetName="OverallAccuracy", 
           col.names=TRUE, row.names=FALSE, append=FALSE, showNA=TRUE)
write.xlsx(class.res, "CrossValResults.xlsx", sheetName="ClassAccuracy", 
           col.names=TRUE, row.names=FALSE, append=TRUE, showNA=TRUE)
write.xlsx(res.mat.all, "CrossValResults.xlsx", sheetName="Confusion", 
           col.names=TRUE, row.names=FALSE, append=TRUE, showNA=TRUE)

#######################################################################
######                     Tables and Plotting                   ######
#######################################################################

### Separate the main matrix and producers, 
### users and overall accuracy into different data frames
res.mat.num <- res.mat.all[res.mat.all[3]!="P" & res.mat.all[4]!="U",]
res.mat.num <- transform(res.mat.num, 
                         Pred = factor(Pred, levels=levels(train[[1]])), 
                                      
                         Obs = factor(Obs, levels=levels(train[[1]])))
res.mat.up <- res.mat.all[res.mat.all[3]=="P" | res.mat.all[4]=="U",]
res.mat.up <- transform(res.mat.up, 
                        Pred = factor(Pred, levels = c(levels(train[[1]]),"P","U")),
                        Obs = factor(Obs, levels = c(levels(train[[1]]),"P","U")))
res.mat.up[res.mat.up$Comb=="PU","Comb"] <- "OA"
highlights <- res.mat.num[res.mat.num[3]==res.mat.num[4],][1:numclass,3:5]

#### Compare between classes ####

# Rename classes for class specific results for consistency
str(class.res)
class.res$Class <- as.factor(class.res$Class)
levels(class.res[[2]])
levels(class.res[[2]]) <- levels(train[[1]])

# Calculate overall true positives and sensitivity for each model run
TP <- aggregate(Vals~ModRun,data=res.mat.num[res.mat.num$Pred == res.mat.num$Obs,],sum)
SEN <- TP[2]/aggregate(Vals~ModRun,data=res.mat.num,sum)[2]

# Calculate overall true negatives and specififity for each model run
negs <- rep(0,length(unique(res.mat.num[1])[[1]]))
tnegs <- rep(0,length(unique(res.mat.num[1])[[1]]))

for (i in unique(res.mat.num[3])[[1]]){
  
  inegs <- aggregate(Vals~ModRun,data=res.mat.num[res.mat.num$Obs != i,],sum)
  negs <- negs+inegs[[2]]
  itnegs <- aggregate(Vals~ModRun,data=res.mat.num[res.mat.num$Obs != i & res.mat.num$Pred != i ,],sum)
  tnegs <- tnegs+itnegs[[2]]
  
  next
}
  
SPE <- tnegs/negs

# Calculate overall balanced accuracy for each model run   
BA <- (SEN+SPE)/2

# Combine values to a matrix
classrestot <- cbind(1:length(SPE),rep("Overall",length(SPE)),SEN,SPE,BA)
names(classrestot) <- names(class.res)

# Add overall accuracy values to class specific table
classvalB <- rbind(class.res,classrestot)

classvalB
str(classvalB)

# Calculate averages and standard deviations for validation statistics across model runs
cavevalsB <- aggregate(x = classvalB[3:5], by = list(classvalB$Class), FUN = "mean")
csdvalsB <- aggregate(x = classvalB[3:5], by = list(classvalB$Class), FUN = "sd")

# Combine values in a table
BCvalsT <- data.frame(Name=cavevalsB[1],
                      SENSmean=round(cavevalsB[2],2),
                      SENSsd=round(csdvalsB[2],2),
                      SPECmean=round(cavevalsB[3],2),
                      SPECsd=round(csdvalsB[3],2),
                      BAmean=round(cavevalsB[4],2),
                      BAsd=round(csdvalsB[4],2))
# Rename columns
names(BCvalsT) <- c("Name","SENSmean","SENSsd","SPECmean","SPECsd",
                    "BAmean","BAsd")
# Print table
BCvalsT
# Write table to Excel
write.xlsx(BCvalsT, "CrossValResults.xlsx", sheetName="ClassStats", 
           col.names=TRUE, row.names=FALSE, append=TRUE, showNA=TRUE)

### Plot the class specific accuracies
str(classvalB)

require(reshape2)
plotterBC <-melt(classvalB,id.vars=c(2),measure.vars=c(3:5))
str(plotterBC)
levels(plotterBC$variable)
levels(plotterBC$variable) <- c("Sensitivity","Specificity","Balanced Accuracy")

require(ggplot2)
require(RColorBrewer)
ssbp <- ggplot(plotterBC,(aes(x=Class,y=value))) +
  geom_boxplot(width=0.7,position=position_dodge(width=0.71),fill="grey40") +
  #scale_fill_manual(values=classpal) +
  facet_wrap(~ variable) +
  ylim(c(0,1)) +
  ggtitle("Accuracy Statistics Per Class") + 
  theme(axis.title.y = element_blank(),
        axis.text.y  = element_text(vjust=0.5, size=12,colour="black"),
        axis.text.x  = element_text(angle=90,vjust=0.5, size=12,colour="black"),
        axis.title.x  = element_blank(),
        plot.title =  element_text(size=14,colour="black", face = "bold",vjust=2, hjust=0.5),
        strip.background = element_rect(fill="grey40"),
        strip.text.x = element_text(size=12, face="bold",colour="white"),
        panel.grid.major = element_line(colour="grey80"),
        panel.grid.minor = element_line(colour="grey80"),
        panel.background = element_rect(fill="white"))

#### Look at the Whole classification ####
class.res.all
classvalB.all <- data.frame(class.res.all,Sens=SEN[[1]],Spec=SPE,BA=BA[[1]])

# Calculate averages and standard deviations for validation statistics
callavevalsB <- colMeans(classvalB.all[2:10])
callsdvalsB <- colSds(as.matrix(classvalB.all[2:10]))

# Combine values in a table
BCallvalsT <- data.frame(Accmean=round(callavevalsB[1],2),
                         Accsd=round(callsdvalsB[1],2),
                         Pmean=round(callavevalsB[3],2),
                         Psd=round(callsdvalsB[3],2),
                         Kmean=round(callavevalsB[4],2),
                         Ksd=round(callsdvalsB[4],2),
                         Qmean=round(callavevalsB[5],2),
                         Qsd=round(callsdvalsB[5],2),
                         Amean=round(callavevalsB[6],2),
                         Asd=round(callsdvalsB[6],2),
                         Sensmean=round(callavevalsB[7],2),
                         Senssd=round(callsdvalsB[7],2),
                         Specmean=round(callavevalsB[8],2),
                         Specsd=round(callsdvalsB[8],2),
                         BAmean=round(callavevalsB[9],2),
                         BAsd=round(callsdvalsB[9],2))

# Rename columns
names(BCallvalsT) <- c("Accmean","Accsd","Pmean","Psd","Kmean","Ksd",
                       "Qmean","Qsd","Amean","Asd","Sensmean","Senssd",
                       "Specmean","Specsd","BAmean","BAsd")

# Print table
BCallvalsT
# Write table to Excel
write.xlsx(BCallvalsT, "CrossValResults.xlsx", sheetName="ModelStats", 
           col.names=TRUE, row.names=FALSE, append=TRUE, showNA=TRUE)

### Plot the range of whole modelvalidation statistics

## Reshape the dataframe for plotting
require(reshape2)
str(classvalB.all)
plotterBCA <-melt(classvalB.all,id.vars=c(1),measure.vars=c(2,3,5:10))
str(plotterBCA)
levels(plotterBCA$variable)
levels(plotterBCA$variable) <- c("Accuracy","NIR","Kappa","Q","A","Sensitivity",
                                "Specificity","Balanced Accuracy")

## Overall accuracy and Kappa stastistic plot - ranges from crossvalidation runs

# Extract Accuracy and Kappa values
plotterBCA2 <- plotterBCA[plotterBCA$variable=="Accuracy"|plotterBCA$variable=="Kappa",]
# Extract NIR value
linevar <- data.frame(variable=c("Accuracy"),Z=mean(plotterBCA[plotterBCA$variable=="NIR",3]))

# Boxplots
ssbpa <- ggplot(plotterBCA2,(aes(x=variable,y=value))) +
  geom_boxplot(width=0.7,position=position_dodge(width=0.71),fill="grey40") +
  geom_hline(data=linevar,aes(yintercept=Z), 
             colour="gray24",
             size=0.6,
             linetype=2) +
  facet_wrap(~ variable,nrow=1,scales = "free_x") +
  ylim(c(0,1)) +
  ggtitle("Overall Accuracy Statistics") + 
  theme(axis.title.y = element_blank(),
        axis.text.y  = element_text(vjust=0.5, size=12,colour="black"),
        axis.text.x  = element_blank(),
        axis.title.x  = element_blank(),
        plot.title =  element_text(size=14,colour="black", face = "bold",vjust=2, hjust=0.5),
        strip.background = element_rect(fill="grey40"),
        strip.text.x = element_text(size=12, face="bold",colour="white"),
        panel.grid.major = element_line(colour="grey80"),
        panel.grid.minor = element_line(colour="grey80"),
        panel.background = element_rect(fill="white"),
        plot.margin = unit(c(0.2, 1,1.6 ,0.3), "cm")) #top, right, bottom, left
ssbpa
### Combine class specific and overall classification plots
# Set up the page for layout 1
require(grid)
lo.main <- nlevels(plotterBC[[1]])*1.1*3
jw <- lo.main + 7

jpeg("AccStats.jpg", width = jw, units = "cm",height = 8,res = 400)
grid.newpage()
# Define layout
pushViewport(viewport(layout = grid.layout(1,2,
                                           heights=unit(c(8),c("cm")),
                                           widths=unit(c(lo.main,7), "cm"))))
#lo.main <- nlevels(plotterBC[[1]])
#grid.newpage()
# Define layout
#pushViewport(viewport(layout = grid.layout(1,2,
#                                           heights=unit(c(1),c("null")),
#                                           widths=unit(c(lo.main,2), "null"))))

# Add plots to layout
print(ssbp,  vp = viewport(layout.pos.row = 1,
                        layout.pos.col = 1))
print(ssbpa, vp = viewport(layout.pos.row = 1,
                        layout.pos.col = 2))

dev.off()

#### Plot of confusion matrix and accuracies ######
library(ggplot2)

### Define the plot of main confusion matrix

## Main plot
p <-  ggplot(res.mat.num,(aes(x=Obs,y=Vals))) +
  geom_boxplot(width=0.7,fill="grey70") +
  facet_grid(Pred~Obs, scales = "free_x") +
  xlab("") +
  ylab("Predicted\n ") +
  ggtitle("Observed\n ") + 
  theme(axis.title.y = element_text(size=13,colour="black", face = "bold",vjust=2),
        axis.text.y  = element_text(vjust=0.5, size=13,colour="black"),
        axis.text.x  = element_blank(),
        axis.title.x  = element_text(size=13,colour="black", face = "bold",vjust=0),
        plot.title =  element_text(size=13,colour="black", face = "bold",vjust=0.7, hjust = 0.5),
        strip.text.x = element_text(size=13, face="bold",colour="white"),
        strip.text.y = element_text(size=13, face="bold",colour="white"),
        strip.background = element_rect(fill="grey30"),
        panel.grid.major = element_line(colour="grey90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill="white",color="grey30", 
                                        size=0.5, linetype="solid"),
        plot.margin = unit(c(0.5, 0, 0,0.7), "cm"))
p

## Add shading to diagonal
fillcol <- "grey28"     # Define based on contrast
p1 <- p + geom_rect(data=highlights,aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf), 
                    fill=fillcol, alpha=0.3) +
  geom_boxplot(data=res.mat.num,aes(x=Obs,y=Vals),width=0.7,fill="grey70")
p1

## Add averages as numbers to plot
# Dataframe with averages ad plotting locations
aggdata <-aggregate(res.mat.num$Vals, by=list(res.mat.num$Pred,res.mat.num$Obs), 
                    FUN=mean, na.rm=TRUE)
names(aggdata) <- c("Pred", "Obs","labs")
aggdata$labs <- round(aggdata$labs,1)
len <- nrow(aggdata)
dat <- data.frame(x = rep(1, len), y = rep(max(res.mat.num$Vals)/2, len), aggdata)
# Add to plot
p1 <- p1 + geom_text(aes(x, y, label=format(labs,round(labs,digits = 1)), group=NULL),data=dat)

p1
### Define plot of the ranges of users accuracies
p2 <-  ggplot(res.mat.up[grep("P",res.mat.up$Comb),],(aes(x=Comb,y=Vals))) +
  geom_boxplot(width=0.7,position=position_dodge(width=0.71),fill="grey70") +
  expand_limits(y=c(0,100)) +
  facet_wrap(~Comb, nrow = 1,scales = "free_x") +
  ylab("Producer's \n Accuracy %") +
  ggtitle("  ") + 
  theme(axis.title.y = element_text(size=13,colour="black", face = "bold",vjust=1.7),
        axis.text.y  = element_text(vjust=0.5, size=13,colour="black"),
        axis.title.x = element_blank(),
        axis.text.x  = element_blank(),
        plot.title =  element_text(size=18,colour="black", face = "bold",vjust=2),
        strip.text.x = element_blank(),
        strip.text.y = element_blank(),
        strip.background = element_blank(),
        panel.grid.major = element_line(colour="grey90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill="white",color="grey30", size=0.5, linetype="solid"),
        plot.margin = unit(c(0.5, 0.7, 0.3, 0.5), "cm"))
p2

### Define plot of the ranges of producers accuracies
p3 <-  ggplot(res.mat.up[grep("U",res.mat.up$Comb),],(aes(x=Comb,y=Vals))) +
  geom_boxplot(width=0.7,position=position_dodge(width=0.71),fill="grey70") +
  expand_limits(y=c(0,100)) +
  facet_wrap(~Comb, ncol=1,scales = "free_x") +
  ggtitle("User's \n Accuracy %\n \n ") + 
  theme(axis.title.y = element_blank(),
        axis.text.y  = element_text(vjust=0.5, size=13,colour="black"),
        axis.title.x = element_blank(),
        axis.text.x  = element_blank(),
        plot.title =  element_text(size=13,colour="black", face = "bold",vjust=0, hjust = 0.5),
        strip.text.x = element_blank(),
        strip.text.y = element_blank(),
        strip.background = element_blank(),
        panel.grid.major = element_line(colour="grey90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill="white",color="grey30", 
                                        size=0.5, linetype="solid"),
        panel.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"),
        plot.margin = unit(c(0.3, 0.5, 0.5, 0.5), "cm"))
p3

### Define plot of the ranges of overall accuracy
p4 <-  ggplot(res.mat.up[grep("OA",res.mat.up$Comb),],(aes(x=Comb,y=Vals))) +
  geom_boxplot(width=0.7,position=position_dodge(width=0.71),fill="grey70") +
  expand_limits(y=c(0,100)) +
  facet_wrap(~Comb, ncol=1,scales = "free_x") +
  ggtitle("Overall \n Accuracy %") + 
  theme(axis.title.y = element_blank(),
        axis.text.y  = element_text(vjust=0.5, size=13,colour="black"),
        axis.title.x = element_blank(),
        axis.text.x  = element_blank(),
        plot.title =  element_text(size=13,colour="black", face = "bold",vjust=0, hjust = 0.5),
        strip.text.x = element_blank(),
        strip.text.y = element_blank(),
        strip.background = element_blank(),
        panel.grid.major = element_line(colour="grey90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill="white",color="grey30", 
                                        size=0.5, linetype="solid"),
        panel.margin = unit(c(-0.5, -0.35, -0.5, -0.35), "cm"),
        plot.margin = unit(c(0.1, 0.5, 0.3, 0.2), "cm"))
p4


## Combine the plots into a single layout

# Set up the page
require(grid)
sq.main <- nlevels(plotterBC[[1]])*3
jhw <- sq.main +4

jpeg("ConfMatrix.jpg",width = jhw,height = jhw,units = "cm",res=400)
grid.newpage()
# Define layout
pushViewport(viewport(layout = grid.layout(2,2,
                                           heights=unit(c(sq.main, 4),c("cm")),
                                           widths=unit(c(sq.main, 4), "cm"))))
# Add plots to layout
print(p1,
      vp = viewport(layout.pos.row = 1,
                    layout.pos.col = 1))
print(p3, vp = viewport(layout.pos.row = 1,
                        layout.pos.col = 2))
print(p2, vp = viewport(layout.pos.row = 2,
                        layout.pos.col = 1))
print(p4, vp = viewport(layout.pos.row = 2,
                        layout.pos.col = 2))
dev.off()

#######################################################################
######           Predictions and Spatial Variability             ######
######                      Pixel Based                          ######
#######################################################################

### Make objects to store crossvalidation predictions
modproSQ <- stack()
extent(modproSQ) <- extent(s1)
modproSQP <- list()

### Add predictions for each crossvalidation models into outputs

for (i in 1:length(modlst)){
  
  # Drop unnecessary predictor layers 
  dr <- names(s1)
  dr <- dr[!dr %in% preds]
  
  s2 <- dropLayer(s1, dr)
  s2
  
  # Predict
  modproSQ <- addLayer(modproSQ, predict(s2,modlst[[i]],type="raw"))
  modproSQP[i] <- predict(s2,modlst[[i]],type="prob",index=1:numclass)
  
  next
}

### Create a raster stack for spatial confidence results
ROutput <- stack()

### Calculate most frequent class and its frequency

# Most frequent class
MaxClass <- modal(modproSQ,freq=FALSE)
ROutput <- addLayer(ROutput,MaxClass)
# Frequency of most frequent class (fraction of runs)
MaxClassF <- modal(modproSQ,freq=TRUE)/nruns
ROutput <- addLayer(ROutput,MaxClassF)

### Calculate average probabilities for classes
modproSQPsums <- Reduce("+", modproSQP)
AvePclass <- modproSQPsums / nruns

### Find average probability of maximum frequency class
MaxClassAveProb <- stackSelect(AvePclass, MaxClass)
ROutput <- addLayer(ROutput,MaxClassAveProb)

### Calculate new layer for frequency x probability
CombConf <- MaxClassF * MaxClassAveProb
ROutput <- addLayer(ROutput,CombConf)

### Rename layers
names(ROutput) <- c("MaxClass","MaxClassF","MaxClassAveProb","CombConf")

### Plot layers 
plot(ROutput)

### Export Raster
writeRaster(ROutput, "Output_Raster_Prediction.tif", bylayer=TRUE, format="GTiff",overwrite=T)
    # Outputs 4 raster files
    # File "1" contains the predicted class for each pixel. Output is an integer number corresponding 
    #     to the order of classes in "class.res.0"
    # File "2" contains the frequency of the most common class for each pixel
    # File "3" contains the value of node purity for each pixel
    # File "4" contains the combined confidence value derived from multiplying the pixel values of 
    #     file 2 and file 3

### Save raster stack to R workspace
save(ROutput,file="Workspace_Raster_Prediction.RData")